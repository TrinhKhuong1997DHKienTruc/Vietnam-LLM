torch>=2.0.0
transformers>=4.36.0
accelerate>=0.20.0
sentencepiece>=0.1.99
protobuf>=3.20.0
numpy>=1.21.0
scipy>=1.7.0
datasets>=2.10.0
huggingface-hub>=0.16.0
einops>=0.6.0
xformers>=0.0.20
bitsandbytes>=0.41.0
optimum>=1.12.0